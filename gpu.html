<!DOCTYPE html>
<html>
<body style="margin:0;overflow:hidden">
<video id="video" muted></video>
<canvas id="canvas"></canvas>
<script type="module">
console.clear();
const video = document.getElementById('video');
await (async () => {
    video.srcObject = await navigator.mediaDevices.getUserMedia({ video: true });
    await video.play();
})();
const adapter = await navigator.gpu.requestAdapter();
const device = await adapter.requestDevice();
const context = document.getElementById('canvas').getContext('webgpu');
const format = navigator.gpu.getPreferredCanvasFormat();
context.configure({ device, format, alphaMode: 'opaque' });
const module = device.createShaderModule({ code: `
@group(0) @binding(0) var samp : sampler;
@group(0) @binding(1) var tex : texture_external;

struct VertexOut { @builtin(position) pos: vec4<f32>, @location(0) uv: vec2<f32> };
@vertex fn vs(@builtin(vertex_index) i: u32) -> VertexOut {
    var pos = array<vec2<f32>, 6>(
        vec2<f32>(-1.0, -1.0), vec2<f32>(1.0, -1.0), vec2<f32>(-1.0, 1.0),
        vec2<f32>(-1.0, 1.0), vec2<f32>(1.0, -1.0), vec2<f32>(1.0, 1.0)
    );
    var uv = (pos[i] + vec2<f32>(1.0)) * 0.5;
    return VertexOut(vec4<f32>(pos[i], 0.0, 1.0), uv);
}
@fragment fn fs(frag: VertexOut) -> @location(0) vec4<f32> {
    return textureSampleBaseClampToEdge(tex, samp, frag.uv);
}`});
const pipeline = device.createRenderPipeline({
    layout: "auto",
    vertex: { module, entryPoint: 'vs' },
    fragment: { module, entryPoint: 'fs', targets: [{ format }] }
});
const sampler = device.createSampler();
const canvas = document.getElementById('canvas');
function frame() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const externalTexture = device.importExternalTexture({ source: video });
    const bindGroup = device.createBindGroup({
        layout: pipeline.getBindGroupLayout(0),
        entries: [
            { binding: 0, resource: sampler },
            { binding: 1, resource: externalTexture }
        ]
    });
    const encoder = device.createCommandEncoder();
    const pass = encoder.beginRenderPass({
        colorAttachments: [{
            view: context.getCurrentTexture().createView(),
            loadOp: 'clear',
            storeOp: 'store',
            clearValue: { r: 0, g: 0, b: 0, a: 1 }
        }]
    });
    pass.setPipeline(pipeline);
    pass.setBindGroup(0, bindGroup);
    pass.draw(6);
    pass.end();
    device.queue.submit([encoder.finish()]);
    requestAnimationFrame(frame);
}
requestAnimationFrame(frame);
</script>
</body>
</html>
